library(NbClust)
data(iris)
iris_features <- iris[, 1:4]
set.seed(123)
# Traženje optimalnog broja klastera (minimum 2, maksimum 6)
nb <- NbClust(data = iris_features, distance = "euclidean", min.nc = 2, max.nc = 6, method = "kmeans")
# Prikaz optimalnog broja klastera prema većini kriterija
bestnc <- nb$Best.nc[1, ]
table(bestnc)
# Traženje optimalnog broja klastera (minimum 2, maksimum 6)
nb <- NbClust(data = iris_features, distance = "euclidean", min.nc = 2, max.nc = 6, method = "kmeans")
# install.packages("NbClust")
library(NbClust)
data(iris)
iris_features <- iris[, 1:4]
set.seed(123)
# Traženje optimalnog broja klastera (minimum 2, maksimum 6)
nb <- NbClust(data = iris_features, distance = "euclidean", min.nc = 2, max.nc = 6, method = "kmeans")
# Prikaz optimalnog broja klastera prema većini kriterija
bestnc <- nb$Best.nc[1, ]
table(bestnc)
View(iris)
# Traženje optimalnog broja klastera (minimum 2, maksimum 6)
nb <- NbClust(data = iris_features, distance = "euclidean", method = "kmeans")
# Prikaz optimalnog broja klastera prema većini kriterija
bestnc <- nb$Best.nc[1, ]
table(bestnc)
# Primjena K-means s K=3
set.seed(123)
# Primjena K-means s K=3
set.seed(123)
kmeans_result <- kmeans(iris_features, centers = 2)
# Klusteri
kmeans_result$cluster
# Veličina klastera
kmeans_result$size
# Postoci klastera
kmeans_result$withinss
# Prikaz rezultata
table(kmeans_result$cluster, iris$Species)
# Vizualizacija
plot(iris_features[, c("Sepal.Length", "Sepal.Width")],
col = kmeans_result$cluster,
main = "K-means grupiranje (K=3)")
points(kmeans_result$centers[, c("Sepal.Length", "Sepal.Width")],
col = 1:3, pch = 8, cex = 2)
# Primjena K-means s K=3
set.seed(123)
kmeans_result <- kmeans(iris_features, centers = 2)
# Klusteri
kmeans_result$cluster
# Veličina klastera
kmeans_result$size
# Postoci klastera
kmeans_result$withinss
# Prikaz rezultata
table(kmeans_result$cluster, iris$Species)
# Vizualizacija
plot(iris_features[, c("Sepal.Length", "Sepal.Width")],
col = kmeans_result$cluster,
main = "K-means grupiranje (K=3)")
points(kmeans_result$centers[, c("Sepal.Length", "Sepal.Width")],
col = 1:3, pch = 8, cex = 2)
data(iris)
iris_features <- iris[, 1:4]
set.seed(123)
# Traženje optimalnog broja klastera (minimum 2, maksimum 6)
nb <- NbClust(data = iris_features, distance = "euclidean", method = "kmeans")
# Prikaz optimalnog broja klastera prema većini kriterija
bestnc <- nb$Best.nc[1, ]
table(bestnc)
# Primjena K-means s K=3
set.seed(123)
kmeans_result <- kmeans(iris_features, centers = 2)
# Klusteri
kmeans_result$cluster
# Veličina klastera
kmeans_result$size
# Postoci klastera
kmeans_result$withinss
# Prikaz rezultata
table(kmeans_result$cluster, iris$Species)
# Vizualizacija
plot(iris_features[, c("Sepal.Length", "Sepal.Width")],
col = kmeans_result$cluster,
main = "K-means grupiranje (K=3)")
points(kmeans_result$centers[, c("Sepal.Length", "Sepal.Width")],
col = 1:3, pch = 8, cex = 2)
# Primjena K-means s K=3
set.seed(123)
kmeans_result <- kmeans(iris_features, centers = 2)
# Klusteri
kmeans_result$cluster
# Veličina klastera
kmeans_result$size
# Postoci klastera
kmeans_result$withinss
# Prikaz rezultata
table(kmeans_result$cluster, iris$Species)
# Vizualizacija
plot(iris_features[, c("Sepal.Length", "Sepal.Width")],
col = kmeans_result$cluster,
main = "K-means grupiranje (K=3)")
points(kmeans_result$centers[, c("Sepal.Length", "Sepal.Width")],
col = 1:3, pch = 8, cex = 2)
set.seed(123)
kmeans_result <- kmeans(iris_features, centers = 2)
# Klusteri
kmeans_result$cluster
# Veličina klastera
kmeans_result$size
# Postoci klastera
kmeans_result$withinss
kmeans_result
# Vizualizacija
plot(iris_features[, c("Sepal.Length", "Sepal.Width")],
col = kmeans_result$cluster,
main = "K-means grupiranje (K=3)")
points(kmeans_result$centers[, c("Sepal.Length", "Sepal.Width")],
col = 1:3, pch = 8, cex = 2)
# Vizualizacija
plot(iris_features[, c("Petal.Length", "Petal.Width")],
col = kmeans_result$cluster,
main = "K-means grupiranje (K=3)")
points(kmeans_result$centers[, c("Petal.Length", "Petal.Width")],
col = 1:3, pch = 8, cex = 2)
# Traženje optimalnog broja klastera (minimum 2, maksimum 6)
nb <- NbClust(data = iris_features, distance = "euclidean", method = "kmeans")
# Primjena K-means s K=3
set.seed(123)
kmeans_result <- kmeans(iris_features, centers = 2)
kmeans_result
# Klusteri
kmeans_result$cluster
# Veličina klastera
kmeans_result$size
# Postoci klastera
kmeans_result$withinss
# install.packages("NbClust")
library(NbClust)
data(iris)
iris_features <- iris[, 1:4]
set.seed(123)
# Traženje optimalnog broja klastera (minimum 2, maksimum 6)
nb <- NbClust(data = iris_features, distance = "euclidean", method = "kmeans")
# Prikaz optimalnog broja klastera prema većini kriterija
bestnc <- nb$Best.nc[1, ]
table(bestnc)
# install.packages("NbClust")
library(NbClust)
data(iris)
iris_features <- iris[, 1:4]
set.seed(123)
# Traženje optimalnog broja klastera (minimum 2, maksimum 6)
nb <- NbClust(data = iris_features, distance = "euclidean", method = "kmeans")
# Prikaz optimalnog broja klastera prema većini kriterija
bestnc <- nb$Best.nc[1, ]
table(bestnc)
# Primjena K-means s K=3
set.seed(123)
kmeans_result <- kmeans(iris_features, centers = 2)
kmeans_result
# Postoci klastera
kmeans_result$betweenss
# Prikaz rezultata
table(kmeans_result$cluster, iris$Species)
# Primjena K-means s K=3
set.seed(123)
kmeans_result <- kmeans(iris_features, centers = 3)
kmeans_result
# Klusteri
kmeans_result$cluster
# Veličina klastera
kmeans_result$size
# Postoci klastera
kmeans_result$withinss
# Postoci klastera
kmeans_result$betweenss
# Prikaz rezultata
table(kmeans_result$cluster, iris$Species)
# Vizualizacija sepal
plot(iris_features[, c("Sepal.Length", "Sepal.Width")],
col = kmeans_result$cluster,
main = "K-means grupiranje (K=3)")
points(kmeans_result$centers[, c("Sepal.Length", "Sepal.Width")],
col = 1:3, pch = 8, cex = 2)
# Vizualizacija petal
plot(iris_features[, c("Petal.Length", "Petal.Width")],
col = kmeans_result$cluster,
main = "K-means grupiranje (K=3)")
points(kmeans_result$centers[, c("Petal.Length", "Petal.Width")],
col = 1:3, pch = 8, cex = 2)
# install.packages("flexclust")
library(flexclust)
# Pretvaranje rezultata u Kcentroids objekt
kcca_model <- as.kcca(kmeans_result, iris_features)
# Dodjela klastera pomoću flexclust metode
clusters_flex <- predict(kcca_model)
# Evaluacija točnosti u odnosu na stvarne klase
table(clusters_flex, iris$Species)
# Preciznost klasifikacije
randIndex(table(clusters_flex, iris$Species))
# install.packages("cluster")
library(cluster)
# Primjena pam algoritma s 3 klastera
set.seed(123)
pam_result <- pam(iris_features, k = 3)
# Prikaz medoida
pam_result$medoids
# Prikaz klastera i usporedba sa stvarnim vrstama
table(pam_result$clustering, iris$Species)
clusplot(iris_features,
kmeans_result$cluster,
color = TRUE, shade = TRUE, labels = 2, lines = 0,
main = "Clusplot prikaz K-means klastera")
clusplot(iris_features,
kmeans_result$cluster,
color = TRUE, shade = TRUE, labels = 2, lines = 0,
main = "Clusplot prikaz K-means klastera")
# Prikaz medoida
pam_result$medoids
# Prikaz klastera i usporedba sa stvarnim vrstama
table(pam_result$clustering, iris$Species)
clusplot(iris_features,
kmeans_result$cluster,
color = TRUE, shade = TRUE, labels = 1, lines = 0,
main = "Clusplot prikaz K-means klastera")
clusplot(iris_features,
kmeans_result$cluster,
color = TRUE, shade = TRUE, labels = 2, lines = 0,
main = "Clusplot prikaz K-means klastera")
clusplot(iris_features,
kmeans_result$cluster,
color = TRUE, shade = TRUE, labels = 3, lines = 0,
main = "Clusplot prikaz K-means klastera")
clusplot(iris_features,
kmeans_result$cluster,
color = TRUE, shade = TRUE, labels = 3, lines = 1,
main = "Clusplot prikaz K-means klastera")
clusplot(iris_features,
kmeans_result$cluster,
color = TRUE, shade = TRUE, labels = 3, lines = 2,
main = "Clusplot prikaz K-means klastera")
clusplot(iris_features,
kmeans_result$cluster,
color = TRUE, shade = TRUE, labels = 3, lines = 3,
main = "Clusplot prikaz K-means klastera")
clusplot(iris_features,
kmeans_result$cluster,
color = TRUE, shade = TRUE, labels = 3, lines = 1,
main = "Clusplot prikaz K-means klastera")
clusplot(iris_features,
kmeans_result$cluster,
color = TRUE, shade = TRUE, labels = 3, lines = 0,
main = "Clusplot prikaz K-means klastera")
# Vizualizacija rasporeda klastera u 2D prostoru
clusplot(iris_features,
pam_result$cluster,
color = TRUE, shade = TRUE, labels = 3, lines = 0,
main = "Clusplot prikaz K-means klastera")
# Vizualizacija rasporeda klastera u 2D prostoru
clusplot(iris_features,
pam_result$cluster,
color = TRUE, shade = TRUE, labels = 3, lines = 0,
main = "Clusplot prikaz PAM klastera")
setwd("~/GitHub/FIPU-APOI/Skripte/Skripta 3. - Korelacija i regresija, vremenski nizovi, klasifikacija i grupacija/Primjeri/zadatak 4")
#1.
library("xlsx")
#1.
titanic <- read.csv("data/primjer.csv")
#1.
titanic <- read.csv("titanik_med.csv")
#1.
titanic <- read.csv("titanic_med.csv")
View(titanic)
set.seed(27)
idx<- sample(nrow(titanic), 0.7*nrow(titanic))
#1. Učitajte podatke iz datoteke `titanic_med.csv` u data frame naziva titanic.
titanic <- read.csv("titanic_med.csv")
set.seed(27)
idx<- sample(nrow(titanic), 0.7*nrow(titanic))
trening <- titanic[idx, ]
test <-titanic[-idx,]
library("rpart")
set.seed(68)
stablo1 <- rpart(Survived~., data = trening, method ="class")
names(stablo1)
stablo1$variable.importance
#5. Grafički prikažite dobiveno stablo.
library("rpart.plot")
rpart.plot(stablo1)
rpart.plot(stablo1, cex=2)
rpart.plot(stablo1, cex=1.5)
rpart.plot(stablo1, cex=1.25)
rpart.plot(stablo1)
rpart.plot(stablo1, cex=1)
rpart.plot(stablo1, cex=0.75)
rpart.plot(stablo1, cex=0.85)
rpart.plot(stablo1, cex=0.9)
rpart.plot(stablo1, cex=1)
rpart.plot(stablo1, cex=0.85)
rpart.plot(stablo1, cex=0.8)
titanic <- read.csv("titanic_med.csv")
# 2. Podatke titanic podijelite slučajnom podjelom
# u omjeru 70:30 na skupove trening i test. Postavite sjeme na 27.
set.seed(27)
idx<- sample(nrow(titanic), 0.7*nrow(titanic))
trening <- titanic[idx, ]
test <-titanic[-idx,]
### Stablo odlučivanja
# 9. Kreirajte stablo odluke za klasifikaciju putnika na preživjele
# i one koji nisu uspjeli preživjeti. Koristite sve varijable.
# Postavite sjeme na 68.
library("rpart")
set.seed(68)
stablo1 <- rpart(Survived~., data = trening, method ="class")
# 4. Koja je varijabla najznačajnija za klasifikaciju putnika
## prema varijabli Survived?
names(stablo1)
stablo1$variable.importance
# spol (sex)
#5. Grafički prikažite dobiveno stablo.
library("rpart.plot")
rpart.plot(stablo1, cex=0.8)
pred1 <- predict(stablo1, newdata = test, type = "class")
pred1 <- predict(stablo1, newdata = test, type = "class")
tocnost <- sum(pred1 == test$Survived)/nrow(test)*100
tocnost
stablo1$cptable
stablo1$cptable
min(stablo1$cptable[,4])
stablo1$cptable
min(stablo1$cptable[,4])
# min. xerror = 0.5406504, xstd = 0.04156712
0.5406504 - 0.04156712 # 0.4812292
0.5406504 + 0.04156712 # 0.564414
stablo1.rezano <- prune(stablo1, cp = 0.01016260 )
#18.
rpart.plot(stablo1.rezano, cex=0.8, fallen.leaves = TRUE)
rpart.plot(stablo1.rezano, cex=0.8, type = 2, extra = 104, fallen.leaves = TRUE)
#18.
rpart.plot(stablo1.rezano, cex=0.8, type = 2, extra = 104, fallen.leaves = TRUE)
rpart.plot(stablo1, cex=0.8)
#18.
rpart.plot(stablo1.rezano, cex=0.8, type = 2, extra = 104, fallen.leaves = TRUE)
stablo1$cptable
stablo1.rezano <- prune(stablo1, cp = 0.01000000      )
#18.
rpart.plot(stablo1.rezano, cex=0.8, type = 2, extra = 104, fallen.leaves = TRUE)
stablo1.rezano <- prune(stablo1, cp = 0.02032520)
#18.
rpart.plot(stablo1.rezano, cex=0.8, type = 2, extra = 104, fallen.leaves = TRUE)
stablo1$cptable
min(stablo1$cptable[,4])
stablo1.rezano <- prune(stablo1, cp = 0.01219512 )
# 18. Grafički prikažite podrezano stablo.
rpart.plot(stablo1.rezano, cex=0.8, type = 2, extra = 104, fallen.leaves = TRUE)
stablo1.rezano <- prune(stablo1, cp = 0.5000000  )
# 18. Grafički prikažite podrezano stablo.
rpart.plot(stablo1.rezano, cex=0.8, type = 2, extra = 104, fallen.leaves = TRUE)
stablo1.rezano <- prune(stablo1, cp = 0.01422764 )
# 18. Grafički prikažite podrezano stablo.
rpart.plot(stablo1.rezano, cex=0.8, type = 2, extra = 104, fallen.leaves = TRUE)
stablo1$cptable
stablo1.rezano <- prune(stablo1, cp = 0.01422764)
# 18. Grafički prikažite podrezano stablo.
rpart.plot(stablo1.rezano, cex=0.8, type = 2, extra = 104, fallen.leaves = TRUE)
# 18. Grafički prikažite podrezano stablo.
rpart.plot(stablo1.rezano, cex=0.8)
# 18. Grafički prikažite podrezano stablo.
rpart.plot(stablo1.rezano, cex=0.8, type = 2, extra = 104)
# 18. Grafički prikažite podrezano stablo.
rpart.plot(stablo1.rezano, cex=0.8, type = 2)
# 18. Grafički prikažite podrezano stablo.
?rpart.plot(stablo1.rezano, cex=0.8, type = 2, extra = 104)
# 18. Grafički prikažite podrezano stablo.
?rpart.plot(stablo1.rezano, cex=0.8, type = 3, extra = 104)
# 18. Grafički prikažite podrezano stablo.
rpart.plot(stablo1.rezano, cex=0.8, type = 3, extra = 104)
# 18. Grafički prikažite podrezano stablo.
rpart.plot(stablo1.rezano, cex=0.8, type = 2, extra = 104)
# 18. Grafički prikažite podrezano stablo.
rpart.plot(stablo1.rezano, cex=0.8, type = 1, extra = 104)
# 18. Grafički prikažite podrezano stablo.
rpart.plot(stablo1.rezano, cex=0.8, type = 2, extra = 104)
# 18. Grafički prikažite podrezano stablo.
rpart.plot(stablo1.rezano, cex=0.8, type = 2, extra = 200)
# 18. Grafički prikažite podrezano stablo.
rpart.plot(stablo1.rezano, cex=0.8, type = 2)
, extra = 200
# 18. Grafički prikažite podrezano stablo.
rpart.plot(stablo1.rezano, cex=0.8, type = 2, extra = 200)
# 18. Grafički prikažite podrezano stablo.
rpart.plot(stablo1.rezano, cex=0.8, type = 2, extra = 200)
# 18. Grafički prikažite podrezano stablo.
rpart.plot(stablo1.rezano, cex=0.8, type = 2, extra = 104)
# 18. Grafički prikažite podrezano stablo.
rpart.plot(stablo1.rezano, cex=0.8, type = 2)
# 18. Grafički prikažite podrezano stablo.
rpart.plot(stablo1.rezano, cex=0.8, type = 2, tweak=1.2)
# 18. Grafički prikažite podrezano stablo.
rpart.plot(stablo1.rezano, cex=0.8, type = 2, tweak=1.5)
# 18. Grafički prikažite podrezano stablo.
rpart.plot(stablo1.rezano, cex=1, type = 2, tweak=1.5)
# 18. Grafički prikažite podrezano stablo.
rpart.plot(stablo1.rezano, cex=1, type = 2, tweak=1)
# 18. Grafički prikažite podrezano stablo.
rpart.plot(stablo1.rezano, cex=1, type = 2, tweak=1.5)
# 18. Grafički prikažite podrezano stablo.
rpart.plot(stablo1.rezano, cex=1.2, type = 2, tweak=1.2)
# 18. Grafički prikažite podrezano stablo.
rpart.plot(stablo1.rezano, cex=1, type = 2, tweak=1.2)
pred2 <- predict(stablo1.rezano, newdata = test, type = "class")
tocnost2 <- sum(pred2 == test$Survived)/nrow(test)*100
tocnost2
library(caret)
confusionMatrix(pred2, test$Survived)
library(caret)
confusionMatrix(pred2, test$Survived)
confusionMatrix(predict, test$Survived)
library(caret)
confusionMatrix(predict, test$Survived)
predict
test$Survived
confusionMatrix(predict, test$Survived)
library(caret)
# Osiguraj da su obje varijable faktori sa istim razinama
pred2 <- factor(pred2, levels = levels(test$Survived))
reference <- factor(test$Survived, levels = levels(test$Survived))
# Kreiranje konfuzijske matrice
confusionMatrix(pred2, reference)
# 19. Podrezano stablo koristite za predviđanje na podacima iz skupa test.
# Koliko iznosi točnost?
pred2 <- predict(stablo1.rezano, newdata = test, type = "class")
tocnost2 <- sum(pred2 == test$Survived)/nrow(test)*100
tocnost2
pred2 <- factor(pred2, levels = levels(test$Survived))
reference <- factor(test$Survived, levels = levels(test$Survived))
cm <- confusionMatrix(pred2, reference)
# Provjeri koje razine postoje u test$Survived
levels(test$Survived)
# Pretpostavimo da su to "0" i "1"
# Osiguraj da i predikcije i stvarne vrijednosti imaju iste razine
pred2 <- factor(pred2, levels = c("0", "1"))
reference <- factor(test$Survived, levels = c("0", "1"))
# Sada možeš sigurno pozvati confusionMatrix
library(caret)
confusionMatrix(pred2, reference))
# Provjeri koje razine postoje u test$Survived
levels(test$Survived)
# Pretpostavimo da su to "0" i "1"
# Osiguraj da i predikcije i stvarne vrijednosti imaju iste razine
pred2 <- factor(pred2, levels = c("0", "1"))
reference <- factor(test$Survived, levels = c("0", "1"))
# Sada možeš sigurno pozvati confusionMatrix
library(caret)
confusionMatrix(pred2, reference)
# 19. Podrezano stablo koristite za predviđanje na podacima iz skupa test.
# Koliko iznosi točnost?
pred2 <- predict(stablo1.rezano, newdata = test, type = "class")
tocnost2 <- sum(pred2 == test$Survived)/nrow(test)*100
tocnost2
pred2
test$Survived
pred2
nrow(pred2)
ncol(pred2)
lengrh(pred2)
length(pred2)
length(test$Survived)
confusionMatrix(pred2, test)
tocnost2 <- sum(pred2 == test$Survived)/nrow(test)*100
tocnost2
### Random Forest
# 14. Koristeći podatke trening kreirajte slučajnu šumu (random forest) i spremite
# u varijablu naziva rf1. Sjeme postavite na 68. Odaberite opciju izračuna važnosti
# varijabli.
library("randomForest")
set.seed(68)
### Random Forest
# 14. Koristeći podatke trening kreirajte slučajnu šumu (random forest) i spremite
# u varijablu naziva rf1. Sjeme postavite na 68. Odaberite opciju izračuna važnosti
# varijabli.
library("randomForest")
set.seed(68)
rf1 <- randomForest(as.factor(Survived)~., data = trening, importance = TRUE)
# 15. Koja je varijabla najznačajnija prema kriteriju prosječnog
# smanjenje točnosti ako se premutiraju vrijednosti varijable?
# Podudara li se to s odgovorom iz zadatka 10?
imp <- importance(rf1, type = 1)
imp
# 16. Za koliko će se smanjiti točnost klasifikacije ako se varijabli Fare
# permutiraju vrijednosti?
imp["Fare"]
# 16. Za koliko će se smanjiti točnost klasifikacije ako se varijabli Fare
# permutiraju vrijednosti?
imp["Fare",]
# 17. Model dobiven pod 14 koristite za za predviđanje na podacima
# iz skupa test. Koliko iznosi točnost?
pred.rf <- predict(rf1, newdata = test)
tocnost.rf <- sum(pred.rf == test$Survived)/nrow(test)*100
tocnost.rf
#18. Koliko stabala sadrži šuma?
names(rf1)
rf1$ntree
set.seed(68)
rf2 <- randomForest(as.factor(Survived)~., data = trening, mtry = 3, ntree = 1000, importance = TRUE)
# 20. Model dobiven pod 24 koristite za za predviđanje
# na podacima iz skupa test. Koliko iznosi točnost?
pred.rf2 <- predict(rf2, newdata = test)
tocnost.rf2 <- sum(pred.rf2 == test$Survived)/nrow(test)*100
tocnost.rf2
